# === LLM API Keys ===
GEMINI_API_KEY=your-gemini-api-key
ANTHROPIC_API_KEY=your-anthropic-api-key
OPENAI_API_KEY=your-openai-api-key
DEEPSEEK_API_KEY=your-deepseek-api-key
# DeepSeek uses OpenAI-compatible API:
# openai.OpenAI(api_key=DEEPSEEK_API_KEY, base_url="https://api.deepseek.com")

# === PostgreSQL (docker image: pgvector/pgvector:pg17) ===
POSTGRES_USER=course_supporter
POSTGRES_PASSWORD=secret
POSTGRES_DB=course_supporter
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
# Composed URL for SQLAlchemy (assembled in config.py from individual vars)
# DATABASE_URL=postgresql+psycopg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}

# === Storage (MinIO â€” S3-compatible) ===
S3_ENDPOINT=http://localhost:9000
S3_ACCESS_KEY=minioadmin
S3_SECRET_KEY=minioadmin
S3_BUCKET=course-materials

# === Redis (task queue backend) ===
REDIS_URL=redis://localhost:6379/0

# === Worker (ARQ task queue) ===
WORKER_MAX_JOBS=2
WORKER_JOB_TIMEOUT=1800
WORKER_MAX_TRIES=3
WORKER_HEAVY_WINDOW_START=02:00
WORKER_HEAVY_WINDOW_END=06:30
WORKER_HEAVY_WINDOW_ENABLED=false
WORKER_HEAVY_WINDOW_TZ=UTC
WORKER_IMMEDIATE_OVERRIDE=true

# === App ===
LOG_LEVEL=DEBUG
ENVIRONMENT=development

# === CORS ===
CORS_ALLOWED_ORIGINS=["http://localhost:3000"]
CORS_ALLOW_CREDENTIALS=false
CORS_ALLOWED_METHODS=["GET","POST"]
CORS_ALLOWED_HEADERS=["Content-Type","X-API-Key"]
