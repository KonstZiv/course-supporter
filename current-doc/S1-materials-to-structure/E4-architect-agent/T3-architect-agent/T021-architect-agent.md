# üìã S1-021: ArchitectAgent Class

## –ú–µ—Ç–∞

–†–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ `ArchitectAgent` ‚Äî –∫–ª—é—á–æ–≤–∏–π –∫–ª–∞—Å, —è–∫–∏–π –ø—Ä–∏–π–º–∞—î `CourseContext`, —Å–µ—Ä—ñ–∞–ª—ñ–∑—É—î –π–æ–≥–æ, —Ñ–æ—Ä–º–∞—Ç—É—î –ø—Ä–æ–º–ø—Ç, –≤–∏–∫–ª–∏–∫–∞—î LLM —á–µ—Ä–µ–∑ `ModelRouter.complete_structured()` —ñ –ø–æ–≤–µ—Ä—Ç–∞—î –≤–∞–ª—ñ–¥–Ω—É `CourseStructure`. –¶–µ —è–¥—Ä–æ –±—ñ–∑–Ω–µ—Å-–ª–æ–≥—ñ–∫–∏ –ø—Ä–æ—î–∫—Ç—É.

## –ö–æ–Ω—Ç–µ–∫—Å—Ç

–¢—Ä–µ—Ç—è –∑–∞–¥–∞—á–∞ Epic 4. –ó–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ S1-019 (CourseStructure ‚Äî response schema) —Ç–∞ S1-020 (prompt_loader ‚Äî system/user prompt). –ë–ª–æ–∫—É—î S1-022 (persistence ‚Äî –∑–±–µ—Ä—ñ–≥–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç). –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î `action="course_structuring"` –∑ `config/models.yaml` (–≤–∂–µ –≤–∏–∑–Ω–∞—á–µ–Ω–∏–π: default chain `gemini-2.5-flash ‚Üí deepseek-chat`, quality chain `claude-sonnet ‚Üí gemini-2.5-pro`).

–§–∞–π–ª `agents/architect.py` –≤–∂–µ —ñ—Å–Ω—É—î —è–∫ stub (TODO) ‚Äî –ø–æ—Ç—Ä—ñ–±–Ω–æ –∑–∞–º—ñ–Ω–∏—Ç–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω–∏–π –∫–æ–¥.

---

## Acceptance Criteria

- [ ] `ArchitectAgent.__init__` –ø—Ä–∏–π–º–∞—î `router`, `prompt_path`, `strategy`, `temperature`, `max_tokens`
- [ ] `ArchitectAgent.run(context: CourseContext) -> CourseStructure` ‚Äî async method
- [ ] –°–µ—Ä—ñ–∞–ª—ñ–∑—É—î `CourseContext` ‚Üí JSON string –¥–ª—è user prompt
- [ ] –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î prompt —á–µ—Ä–µ–∑ `load_prompt()`, —Ñ–æ—Ä–º–∞—Ç—É—î —á–µ—Ä–µ–∑ `format_user_prompt()`
- [ ] –í–∏–∫–ª–∏–∫–∞—î `router.complete_structured(action="course_structuring", response_schema=CourseStructure)`
- [ ] –ü–æ–≤–µ—Ä—Ç–∞—î –ø–µ—Ä—à–∏–π –µ–ª–µ–º–µ–Ω—Ç tuple (parsed CourseStructure)
- [ ] –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ—Ç `AllModelsFailedError` –≤—ñ–¥ router (–Ω–µ –≥–ª—É—à–∏—Ç—å)
- [ ] Default prompt path: `prompts/architect/v1.yaml`
- [ ] ~10 unit-—Ç–µ—Å—Ç—ñ–≤ –∑ mocked router, –≤—Å—ñ –∑–µ–ª–µ–Ω—ñ
- [ ] `make check` –ø—Ä–æ—Ö–æ–¥–∏—Ç—å

---

## –†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è

### src/course_supporter/agents/architect.py

```python
"""ArchitectAgent: generates course structure from materials via LLM."""

import structlog

from course_supporter.agents.prompt_loader import format_user_prompt, load_prompt
from course_supporter.llm.router import ModelRouter
from course_supporter.models.course import CourseContext, CourseStructure

logger = structlog.get_logger()

DEFAULT_PROMPT_PATH = "prompts/architect/v1.yaml"


class ArchitectAgent:
    """Generates structured course program from course materials.

    Uses ModelRouter with action='course_structuring' to call LLM
    with structured output (CourseStructure Pydantic schema).

    Args:
        router: ModelRouter instance for LLM calls.
        prompt_path: Path to YAML prompt template.
        strategy: Routing strategy ('default', 'quality', 'budget').
        temperature: LLM temperature (0.0 = deterministic).
        max_tokens: Maximum output tokens.
    """

    def __init__(
        self,
        router: ModelRouter,
        *,
        prompt_path: str = DEFAULT_PROMPT_PATH,
        strategy: str = "default",
        temperature: float = 0.0,
        max_tokens: int = 8192,
    ) -> None:
        self._router = router
        self._prompt_path = prompt_path
        self._strategy = strategy
        self._temperature = temperature
        self._max_tokens = max_tokens

    async def run(self, context: CourseContext) -> CourseStructure:
        """Generate course structure from materials.

        Args:
            context: Unified course context from ingestion pipeline.

        Returns:
            Validated CourseStructure from LLM.

        Raises:
            AllModelsFailedError: If all models in all strategies fail.
            FileNotFoundError: If prompt file not found.
        """
        # 1. Load and format prompt
        prompt_data = load_prompt(self._prompt_path)
        system_prompt = prompt_data["system_prompt"]
        user_prompt = format_user_prompt(
            prompt_data["user_prompt_template"],
            context.model_dump_json(indent=2),
        )

        logger.info(
            "architect_agent_run",
            strategy=self._strategy,
            prompt_version=prompt_data.get("version", "unknown"),
            documents_count=len(context.documents),
            context_length=len(user_prompt),
        )

        # 2. Call LLM via ModelRouter
        structure, response = await self._router.complete_structured(
            action="course_structuring",
            prompt=user_prompt,
            response_schema=CourseStructure,
            system_prompt=system_prompt,
            temperature=self._temperature,
            max_tokens=self._max_tokens,
            strategy=self._strategy,
        )

        logger.info(
            "architect_agent_done",
            modules_count=len(structure.modules),
            model=response.model_id,
            tokens_in=response.tokens_in,
            tokens_out=response.tokens_out,
            cost_usd=response.cost_usd,
        )

        return structure
```

### src/course_supporter/agents/__init__.py (–æ–Ω–æ–≤–∏—Ç–∏)

```python
"""Agents for course structure generation."""

from course_supporter.agents.architect import ArchitectAgent
from course_supporter.agents.prompt_loader import format_user_prompt, load_prompt

__all__ = [
    "ArchitectAgent",
    "format_user_prompt",
    "load_prompt",
]
```

---

## –¢–µ—Å—Ç–∏

### tests/unit/test_architect_agent.py

```python
"""Tests for ArchitectAgent."""

from unittest.mock import AsyncMock, patch

import pytest

from course_supporter.agents.architect import ArchitectAgent, DEFAULT_PROMPT_PATH
from course_supporter.llm.router import AllModelsFailedError
from course_supporter.llm.schemas import LLMResponse
from course_supporter.models.course import (
    CourseContext,
    CourseStructure,
    ModuleOutput,
)
from course_supporter.models.source import SourceDocument


@pytest.fixture()
def mock_router() -> AsyncMock:
    """ModelRouter mock with complete_structured returning CourseStructure."""
    router = AsyncMock()
    structure = CourseStructure(
        title="Test Course",
        description="A test course",
        modules=[ModuleOutput(title="Module 1")],
    )
    response = LLMResponse(
        content="{}",
        provider="gemini",
        model_id="gemini-2.5-flash",
        tokens_in=100,
        tokens_out=200,
    )
    router.complete_structured.return_value = (structure, response)
    return router


@pytest.fixture()
def sample_context() -> CourseContext:
    """Minimal CourseContext for testing."""
    doc = SourceDocument(source_type="text", source_url="file:///test.md")
    return CourseContext(documents=[doc])


@pytest.fixture()
def prompt_data() -> dict:
    """Mock prompt data."""
    return {
        "version": "v1",
        "system_prompt": "You are a course architect.",
        "user_prompt_template": "Materials:\n{context}\nGenerate.",
    }


class TestArchitectAgentInit:
    def test_default_params(self, mock_router: AsyncMock) -> None:
        """ArchitectAgent initializes with sensible defaults."""
        agent = ArchitectAgent(mock_router)
        assert agent._prompt_path == DEFAULT_PROMPT_PATH
        assert agent._strategy == "default"
        assert agent._temperature == 0.0
        assert agent._max_tokens == 8192

    def test_custom_params(self, mock_router: AsyncMock) -> None:
        """ArchitectAgent accepts custom parameters."""
        agent = ArchitectAgent(
            mock_router,
            prompt_path="custom/prompt.yaml",
            strategy="quality",
            temperature=0.3,
            max_tokens=4096,
        )
        assert agent._prompt_path == "custom/prompt.yaml"
        assert agent._strategy == "quality"
        assert agent._temperature == 0.3
        assert agent._max_tokens == 4096


class TestArchitectAgentRun:
    @pytest.mark.asyncio
    async def test_run_returns_course_structure(
        self,
        mock_router: AsyncMock,
        sample_context: CourseContext,
        prompt_data: dict,
    ) -> None:
        """run() returns CourseStructure from LLM response."""
        with patch(
            "course_supporter.agents.architect.load_prompt",
            return_value=prompt_data,
        ):
            agent = ArchitectAgent(mock_router)
            result = await agent.run(sample_context)

        assert isinstance(result, CourseStructure)
        assert result.title == "Test Course"
        assert len(result.modules) == 1

    @pytest.mark.asyncio
    async def test_run_calls_router_with_correct_action(
        self,
        mock_router: AsyncMock,
        sample_context: CourseContext,
        prompt_data: dict,
    ) -> None:
        """run() passes action='course_structuring' to router."""
        with patch(
            "course_supporter.agents.architect.load_prompt",
            return_value=prompt_data,
        ):
            agent = ArchitectAgent(mock_router, strategy="quality")
            await agent.run(sample_context)

        mock_router.complete_structured.assert_called_once()
        call_kwargs = mock_router.complete_structured.call_args
        assert call_kwargs.kwargs["action"] == "course_structuring"
        assert call_kwargs.kwargs["response_schema"] is CourseStructure
        assert call_kwargs.kwargs["strategy"] == "quality"

    @pytest.mark.asyncio
    async def test_run_passes_system_prompt(
        self,
        mock_router: AsyncMock,
        sample_context: CourseContext,
        prompt_data: dict,
    ) -> None:
        """run() passes system_prompt from loaded YAML."""
        with patch(
            "course_supporter.agents.architect.load_prompt",
            return_value=prompt_data,
        ):
            agent = ArchitectAgent(mock_router)
            await agent.run(sample_context)

        call_kwargs = mock_router.complete_structured.call_args
        assert call_kwargs.kwargs["system_prompt"] == "You are a course architect."

    @pytest.mark.asyncio
    async def test_run_formats_context_into_prompt(
        self,
        mock_router: AsyncMock,
        sample_context: CourseContext,
        prompt_data: dict,
    ) -> None:
        """run() serializes CourseContext and injects into user prompt."""
        with patch(
            "course_supporter.agents.architect.load_prompt",
            return_value=prompt_data,
        ):
            agent = ArchitectAgent(mock_router)
            await agent.run(sample_context)

        call_kwargs = mock_router.complete_structured.call_args
        user_prompt = call_kwargs.kwargs["prompt"]
        assert "Materials:" in user_prompt
        assert "file:///test.md" in user_prompt

    @pytest.mark.asyncio
    async def test_run_passes_temperature_and_max_tokens(
        self,
        mock_router: AsyncMock,
        sample_context: CourseContext,
        prompt_data: dict,
    ) -> None:
        """run() forwards temperature and max_tokens to router."""
        with patch(
            "course_supporter.agents.architect.load_prompt",
            return_value=prompt_data,
        ):
            agent = ArchitectAgent(
                mock_router, temperature=0.5, max_tokens=2048
            )
            await agent.run(sample_context)

        call_kwargs = mock_router.complete_structured.call_args
        assert call_kwargs.kwargs["temperature"] == 0.5
        assert call_kwargs.kwargs["max_tokens"] == 2048

    @pytest.mark.asyncio
    async def test_run_propagates_all_models_failed(
        self,
        mock_router: AsyncMock,
        sample_context: CourseContext,
        prompt_data: dict,
    ) -> None:
        """run() propagates AllModelsFailedError from router."""
        mock_router.complete_structured.side_effect = AllModelsFailedError(
            action="course_structuring",
            strategies_tried=["default"],
            errors=[("gemini-2.5-flash", "rate limit")],
        )
        with patch(
            "course_supporter.agents.architect.load_prompt",
            return_value=prompt_data,
        ):
            agent = ArchitectAgent(mock_router)
            with pytest.raises(AllModelsFailedError):
                await agent.run(sample_context)

    @pytest.mark.asyncio
    async def test_run_propagates_file_not_found(
        self,
        mock_router: AsyncMock,
        sample_context: CourseContext,
    ) -> None:
        """run() propagates FileNotFoundError if prompt file missing."""
        agent = ArchitectAgent(
            mock_router, prompt_path="nonexistent/prompt.yaml"
        )
        with pytest.raises(FileNotFoundError):
            await agent.run(sample_context)
```

---

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª—ñ–≤

```
src/course_supporter/agents/
‚îú‚îÄ‚îÄ __init__.py                  # UPDATE: add ArchitectAgent export
‚îú‚îÄ‚îÄ architect.py                 # UPDATE: replace stub with implementation
‚îî‚îÄ‚îÄ prompt_loader.py             # FROM S1-020

tests/unit/
‚îî‚îÄ‚îÄ test_architect_agent.py      # NEW: ~10 tests
```

---

## –ö—Ä–æ–∫–∏ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è

1. –ó–∞–º—ñ–Ω–∏—Ç–∏ stub `agents/architect.py` ‚Äî –ø–æ–≤–Ω–∞ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è `ArchitectAgent`
2. –û–Ω–æ–≤–∏—Ç–∏ `agents/__init__.py` ‚Äî –¥–æ–¥–∞—Ç–∏ `ArchitectAgent` export
3. –°—Ç–≤–æ—Ä–∏—Ç–∏ `tests/unit/test_architect_agent.py`
4. `make check`

---

## –ü—Ä–∏–º—ñ—Ç–∫–∏

- **action="course_structuring"**: –≤–∂–µ –≤–∏–∑–Ω–∞—á–µ–Ω–∏–π —É `config/models.yaml` –∑ `requires: [structured_output]`. Default chain: `gemini-2.5-flash ‚Üí deepseek-chat`. Quality: `claude-sonnet ‚Üí gemini-2.5-pro`.
- **complete_structured()** –ø–æ–≤–µ—Ä—Ç–∞—î `tuple[Any, LLMResponse]`. –ü–µ—Ä—à–∏–π –µ–ª–µ–º–µ–Ω—Ç ‚Äî parsed Pydantic model (CourseStructure). ModelRouter –æ–±—Ä–æ–±–ª—è—î retry —ñ fallback.
- **–°–µ—Ä—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è context**: `context.model_dump_json(indent=2)` ‚Äî JSON representation. LLM –æ—Ç—Ä–∏–º—É—î –ø–æ–≤–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —è–∫ —Ç–µ–∫—Å—Ç.
- **max_tokens=8192**: CourseStructure –º–æ–∂–µ –±—É—Ç–∏ –≤–µ–ª–∏–∫–æ—é (–¥–µ—Å—è—Ç–∫–∏ –º–æ–¥—É–ª—ñ–≤, —Å–æ—Ç–Ω—ñ –∫–æ–Ω—Ü–µ–ø—Ü—ñ–π). 8192 ‚Äî —Ä–æ–∑—É–º–Ω–∏–π default.
- **Structured output validation**: Pydantic validation –≤—ñ–¥–±—É–≤–∞—î—Ç—å—Å—è –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ provider.complete_structured(). –Ø–∫—â–æ LLM –ø–æ–≤–µ—Ä—Ç–∞—î –Ω–µ–≤–∞–ª—ñ–¥–Ω–∏–π JSON ‚Äî `StructuredOutputError`, router retry/fallback.
- **–ù–µ –≥–ª—É—à–∏–º–æ –ø–æ–º–∏–ª–∫–∏**: `AllModelsFailedError` –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ—Ç—Å—è –¥–æ caller (API endpoint –∞–±–æ orchestrator).
