# üìã S1-009: ModelRouter

## –ú–µ—Ç–∞

–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞ —Ç–æ—á–∫–∞ –¥–ª—è –≤—Å—ñ—Ö LLM-–≤–∏–∫–ª–∏–∫—ñ–≤. –ü—Ä–∏–π–º–∞—î action + prompt + optional strategy, –æ–±–∏—Ä–∞—î chain –º–æ–¥–µ–ª–µ–π, –æ–±—Ä–æ–±–ª—è—î retry/fallback –¥–≤–æ—Ö —Ä—ñ–≤–Ω—ñ–≤: –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ chain (–º–æ–¥–µ–ª—å ‚Üí –º–æ–¥–µ–ª—å) —Ç–∞ –º—ñ–∂ strategies (requested chain –≤–ø–∞–≤ ‚Üí default chain). –ü–µ—Ä–µ–≤—ñ—Ä—è—î `provider.enabled` –ø–µ—Ä–µ–¥ –≤–∏–∫–ª–∏–∫–æ–º. –ö–ª–∞—Å–∏—Ñ—ñ–∫—É—î –ø–æ–º–∏–ª–∫–∏: permanent (401, 403) ‚Äî skip –æ–¥—Ä–∞–∑—É, transient (429, 500) ‚Äî retry.

## –ö–æ–Ω—Ç–µ–∫—Å—Ç

–ó–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ S1-007 (providers –∑ enable/disable) —Ç–∞ S1-008 (registry –∑ strategies). –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è —É—Å—ñ–º–∞ –Ω–∞—Å—Ç—É–ø–Ω–∏–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏.

---

## Acceptance Criteria

- [x] `router.complete(action, prompt)` ‚Äî default strategy, fallback –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ chain
- [x] `router.complete(action, prompt, strategy="quality")` ‚Äî explicit strategy
- [x] Disabled provider ‚Üí skip, try next –≤ chain
- [x] –í–µ—Å—å requested chain –≤–ø–∞–≤ ‚Üí fallback –Ω–∞ `default` strategy (—è–∫—â–æ –Ω–µ –≤–∂–µ default)
- [x] –í—Å—ñ strategies –≤–∏—á–µ—Ä–ø–∞–Ω—ñ ‚Üí `AllModelsFailedError` –∑ –¥–µ—Ç–∞–ª—è–º–∏
- [x] Retry –¥–æ max_attempts –Ω–∞ –∫–æ–∂–Ω—É –º–æ–¥–µ–ª—å (transient errors only)
- [x] Permanent errors (401, 403, 400, 404) ‚Üí skip –º–æ–¥–µ–ª—å –æ–¥—Ä–∞–∑—É, –±–µ–∑ retry
- [x] Cost enrichment ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π `cost_usd` —á–µ—Ä–µ–∑ `ModelConfig.estimate_cost()`
- [x] LogCallback –¥–ª—è –∑–∞–ø–∏—Å—É –≤ DB (S1-010)
- [x] action/strategy –ø—Ä–æ—Å—Ç–∞–≤–ª—è—é—Ç—å—Å—è –≤ LLMResponse
- [x] `request.model` = `model_cfg.model_id` ‚Äî –ø—Ä–æ–≤–∞–π–¥–µ—Ä –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É –º–æ–¥–µ–ª—å –∑ chain
- [x] DRY: complete/complete_structured —á–µ—Ä–µ–∑ —Å–ø—ñ–ª—å–Ω–∏–π `_execute_with_fallback`

---

## –ó–º—ñ–Ω–∏ –≤ —ñ—Å–Ω—É—é—á–∏—Ö —Ñ–∞–π–ª–∞—Ö

### src/course_supporter/llm/schemas.py

–î–æ–¥–∞–Ω–æ –ø–æ–ª–µ `model` –≤ `LLMRequest`:

```python
class LLMRequest(BaseModel):
    prompt: str
    system_prompt: str | None = None
    model: str = ""  # set by ModelRouter; providers fall back to default_model
    temperature: float = 0.0
    max_tokens: int = 4096
    action: str = ""
    strategy: str = "default"
```

### –ü—Ä–æ–≤–∞–π–¥–µ—Ä–∏ (gemini.py, anthropic.py, openai_compat.py)

–ö–æ–∂–µ–Ω –ø—Ä–æ–≤–∞–π–¥–µ—Ä —Ç–µ–ø–µ—Ä –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î `request.model or self._default_model`:

```python
async def complete(self, request: LLMRequest) -> LLMResponse:
    model = request.model or self._default_model
    # ... SDK call –∑ model, LLMResponse –∑ model_id=model
```

–¶–µ –¥–æ–∑–≤–æ–ª—è—î router-—É –ø–µ—Ä–µ–¥–∞–≤–∞—Ç–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É –º–æ–¥–µ–ª—å –∑ chain (–Ω–∞–ø—Ä. `gemini-2.5-pro` –∑–∞–º—ñ—Å—Ç—å –¥–µ—Ñ–æ–ª—Ç–Ω–æ–≥–æ `gemini-2.5-flash`).

---

## src/course_supporter/llm/router.py

```python
"""ModelRouter -- central entry point for all LLM calls.

Two-level fallback:
1. Within chain: model 1 -> model 2 -> model 3
2. Between strategies: quality chain failed -> fallback to default chain
"""

from collections.abc import Awaitable, Callable
from typing import Any

import structlog
from pydantic import BaseModel

from course_supporter.llm.providers.base import LLMProvider, StructuredOutputError
from course_supporter.llm.registry import ModelConfig, ModelRegistryConfig
from course_supporter.llm.schemas import LLMRequest, LLMResponse

logger = structlog.get_logger()

LogCallback = Callable[[LLMResponse, bool, str | None], Awaitable[None]]


class AllModelsFailedError(Exception):
    """All models in all attempted strategies failed."""

    def __init__(
        self,
        action: str,
        strategies_tried: list[str],
        errors: list[tuple[str, str]],
    ) -> None:
        self.action = action
        self.strategies_tried = strategies_tried
        self.errors = errors
        details = "; ".join(f"{m}: {e}" for m, e in errors)
        super().__init__(
            f"All models failed for action '{action}' "
            f"(strategies: {strategies_tried}): {details}"
        )


class ModelRouter:
    """Routes LLM requests with strategy-based fallback."""

    def __init__(
        self,
        providers: dict[str, LLMProvider],
        registry: ModelRegistryConfig,
        log_callback: LogCallback | None = None,
        max_attempts: int = 2,
    ) -> None:
        self._providers = providers
        self._registry = registry
        self._log_callback = log_callback
        self._max_attempts = max_attempts

    # -- public API -------------------------------------------------

    async def complete(
        self, action: str, prompt: str, *,
        system_prompt: str | None = None,
        temperature: float = 0.0,
        max_tokens: int = 4096,
        strategy: str = "default",
    ) -> LLMResponse:
        """Generate text completion with strategy-based fallback."""
        request = LLMRequest(...)

        async def call_fn(provider, req) -> LLMResponse:
            return await provider.complete(req)

        return await self._execute_with_fallback(
            action, strategy, request, call_fn,
        )

    async def complete_structured(
        self, action: str, prompt: str,
        response_schema: type[BaseModel], *,
        system_prompt: str | None = None,
        temperature: float = 0.0,
        max_tokens: int = 4096,
        strategy: str = "default",
    ) -> tuple[Any, LLMResponse]:
        """Generate structured output with strategy-based fallback."""
        request = LLMRequest(...)

        async def call_fn(provider, req) -> tuple[Any, LLMResponse]:
            return await provider.complete_structured(req, response_schema)

        return await self._execute_with_fallback(
            action, strategy, request, call_fn,
        )

    # -- internal: strategy fallback --------------------------------

    async def _execute_with_fallback(
        self, action, strategy, request, call_fn,
    ) -> Any:
        """Two-level fallback: requested strategy -> default."""
        # 1. Try requested strategy chain
        # 2. If failed and strategy != "default" ‚Üí try default chain
        # 3. All failed ‚Üí AllModelsFailedError
        # On cross-strategy fallback: strategy = "quality->default"

    # -- internal: chain iteration ----------------------------------

    async def _try_chain(
        self, action, strategy, request, call_fn, errors,
    ) -> Any | None:
        """Walk model chain. Sets request.model = model_cfg.model_id."""
        chain = self._registry.get_chain(action, strategy)
        for model_cfg in chain:
            provider = self._get_active_provider(model_cfg, errors)
            if provider is None:
                continue
            request_for_model = request.model_copy(
                update={"model": model_cfg.model_id},
            )
            result = await self._try_with_retries(...)
            if result is not None:
                return result
        return None

    def _get_active_provider(
        self, model_cfg: ModelConfig, errors,
    ) -> LLMProvider | None:
        """Check provider exists and is enabled."""

    # -- internal: retry loop ---------------------------------------

    async def _try_with_retries(
        self, provider, request, model_cfg, call_fn, errors, action, strategy,
    ) -> Any | None:
        """Retry call_fn up to max_attempts. Permanent errors ‚Üí break."""
        for attempt in range(1, self._max_attempts + 1):
            try:
                result = await call_fn(provider, request)
                self._enrich_response(result, model_cfg, action, strategy)
                await self._log_success(result)
                return result
            except Exception as exc:
                if not self._is_retryable(exc):
                    # 401, 403 etc ‚Äî skip model immediately
                    break
                if attempt == self._max_attempts:
                    errors.append(...)
        return None

    # -- helpers ----------------------------------------------------

    @staticmethod
    def _is_retryable(exc: Exception) -> bool:
        """Duck-typed error classification (no SDK imports).

        - StructuredOutputError ‚Üí retryable (LLM may produce valid JSON)
        - exc.status_code in (400, 401, 403, 404) ‚Üí permanent
        - exc.code in (400, 401, 403, 404) ‚Üí permanent (google-genai)
        - Everything else ‚Üí retryable (fail-safe default)
        """

    @staticmethod
    def _enrich_response(result, model_cfg, action, strategy) -> None:
        """Set action, strategy, cost_usd on LLMResponse."""

    @staticmethod
    def _set_strategy_path(result, strategy_path: str) -> None:
        """Set strategy on cross-strategy fallback."""

    async def _log_success(self, result) -> None: ...
    async def _log_failure(self, model_cfg, request, error) -> None: ...
    async def _log(self, response, *, success, error_message=None) -> None:
        """Structlog + optional LogCallback."""
```

---

## src/course_supporter/llm/__init__.py

```python
"""LLM infrastructure: providers, schemas, router, registry."""

from course_supporter.llm.router import AllModelsFailedError, ModelRouter
from course_supporter.llm.schemas import LLMRequest, LLMResponse

__all__ = ["AllModelsFailedError", "LLMRequest", "LLMResponse", "ModelRouter"]
```

---

## –¢–µ—Å—Ç–∏

### tests/unit/test_llm/test_router.py

24 —Ç–µ—Å—Ç–∏, `asyncio_mode = "auto"` (–±–µ–∑ `@pytest.mark.asyncio`):

| –ö–ª–∞—Å | –¢–µ—Å—Ç–∏ |
|------|-------|
| `TestDefaultStrategy` | primary succeeds; fallback within chain |
| `TestExplicitStrategy` | quality chain order respected |
| `TestCrossStrategyFallback` | quality‚Üídefault; default doesn't self-fallback |
| `TestDisabledProvider` | skip disabled |
| `TestMissingProvider` | provider not in dict ‚Üí skip |
| `TestAllFail` | both strategies tried; error details populated |
| `TestCostEnrichment` | cost with tokens; cost None without tokens |
| `TestLogCallback` | callback called; success flag passed |
| `TestRetryBehavior` | retries up to max_attempts; retry then success |
| `TestPermanentError` | 401 ‚Üí call_count=1 (no retries) |
| `TestCompleteStructured` | structured success; structured fallback |
| `TestModelIdPassedToProvider` | request.model == model_id from chain |
| `TestIsRetryable` | StructuredOutputError, 401, 429, 500, generic |

Test helpers –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å `ModelRegistryConfig.model_validate()` –∑ dict-based –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—î—é (–≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î —Ä–µ–∞–ª—å–Ω—ñ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ñ `ModelConfig` –∑ `CostPer1K`).

---

## –ü—Ä–∏–º—ñ—Ç–∫–∏

- **Cross-strategy fallback** ‚Äî –ª–∏—à–µ `requested ‚Üí default`. –ü—Ä–æ—Å—Ç–∏–π —ñ –ø–µ—Ä–µ–¥–±–∞—á—É–≤–∞–Ω–∏–π.
- **`strategy="quality->default"`** ‚Äî response.strategy –ø–æ–∫–∞–∑—É—î —Ñ–∞–∫—Ç–∏—á–Ω–∏–π —à–ª—è—Ö (ASCII arrow).
- **Disabled provider** ‚Äî skip, –Ω–µ error. Runtime –≤—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –±–µ–∑ –≤–ø–ª–∏–≤—É –Ω–∞ —ñ–Ω—à—ñ.
- **Missing provider** ‚Äî —è–∫—â–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä –∑ registry –Ω–µ —Å–∫–æ–Ω—Ñ—ñ–≥—É—Ä–æ–≤–∞–Ω–∏–π, skip –∑ error "provider not configured".
- **LogCallback**: `Callable[[LLMResponse, bool, str | None], Awaitable[None]]`. Action/strategy –≤–∂–µ –≤ LLMResponse.
- **DRY**: `complete()` —ñ `complete_structured()` ‚Äî —Ç–æ–Ω–∫—ñ –æ–±–≥–æ—Ä—Ç–∫–∏ –∑ `call_fn` closure, –¥–µ–ª–µ–≥—É—é—Ç—å `_execute_with_fallback`. 6 –º–µ—Ç–æ–¥—ñ–≤ –∑—ñ —Å–ø–µ—Ü–∏—Ñ—ñ–∫–∞—Ü—ñ—ó ‚Üí 2 public + 1 fallback + 1 chain + 1 retry + helpers.
- **`max_attempts`** (–Ω–µ `max_retries`): `max_attempts=2` = 2 —Å–ø—Ä–æ–±–∏ (initial + 1 retry).
- **Error classification**: duck-typed —á–µ—Ä–µ–∑ `getattr(exc, "status_code", None)` ‚Äî –±–µ–∑ —ñ–º–ø–æ—Ä—Ç—É SDK-—Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω–∏—Ö –∫–ª–∞—Å—ñ–≤.
- **Auto-disable**: –≤—ñ–¥–∫–ª–∞–¥–µ–Ω–æ. –ü–æ—Ç–æ—á–Ω–∞ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è –ª–æ–≥—É—î permanent errors —ñ –ø—Ä–æ–ø—É—Å–∫–∞—î –º–æ–¥–µ–ª—å, –∞–ª–µ –Ω–µ –≤—ñ–¥–∫–ª—é—á–∞—î –ø—Ä–æ–≤–∞–π–¥–µ—Ä –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ.
