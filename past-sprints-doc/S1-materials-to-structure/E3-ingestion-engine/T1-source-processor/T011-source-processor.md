# üìã S1-011: SourceProcessor Interface + Pydantic Schemas

## –ú–µ—Ç–∞

–í–∏–∑–Ω–∞—á–∏—Ç–∏ –±–∞–∑–æ–≤–∏–π –∫–æ–Ω—Ç—Ä–∞–∫—Ç –¥–ª—è –æ–±—Ä–æ–±–∫–∏ –∫—É—Ä—Å–æ–≤–∏—Ö –º–∞—Ç–µ—Ä—ñ–∞–ª—ñ–≤ —Ç–∞ Pydantic-–º–æ–¥–µ–ª—ñ –¥–ª—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è –æ–±—Ä–æ–±–ª–µ–Ω–∏—Ö –¥–∞–Ω–∏—Ö. `SourceProcessor` ABC –∑–∞–¥–∞—î —Å–∏–≥–Ω–∞—Ç—É—Ä—É `process(source, *, router=None) -> SourceDocument`. Pydantic-–º–æ–¥–µ–ª—ñ (`ContentChunk`, `SourceDocument`, `CourseContext`) –æ–ø–∏—Å—É—é—Ç—å —É–Ω—ñ—Ñ—ñ–∫–æ–≤–∞–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç –≤–∏—Ö–æ–¥—É –≤—Å—ñ—Ö –ø—Ä–æ—Ü–µ—Å–æ—Ä—ñ–≤.

## –ö–æ–Ω—Ç–µ–∫—Å—Ç

–ü–µ—Ä—à–∞ –∑–∞–¥–∞—á–∞ Epic 3 (Ingestion Engine). –ë–ª–æ–∫—É—î –≤—Å—ñ —ñ–Ω—à—ñ –∑–∞–¥–∞—á—ñ Epic 3 (–∫—Ä—ñ–º S1-018). Epic 1‚Äì2 –∑–∞–≤–µ—Ä—à–µ–Ω—ñ (84 —Ç–µ—Å—Ç–∏). –§–∞–π–ª–∏-–∑–∞–≥–ª—É—à–∫–∏ (`models/source.py`, `models/course.py`, `ingestion/base.py`) –≤–∂–µ —ñ—Å–Ω—É—é—Ç—å ‚Äî –ø–æ—Ç—Ä—ñ–±–Ω–æ –∑–∞–º—ñ–Ω–∏—Ç–∏ TODO –Ω–∞ —Ä–µ–∞–ª—å–Ω–∏–π –∫–æ–¥.

---

## Acceptance Criteria

- [ ] `ChunkType` StrEnum –∑ 7 –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏
- [ ] `ContentChunk` Pydantic model –∑ defaults (empty dict metadata, index=0)
- [ ] `SourceDocument` Pydantic model –∑ auto `processed_at`
- [ ] `SlideVideoMapEntry` ‚Äî Pydantic mirror –¥–ª—è ORM `SlideVideoMapping`
- [ ] `CourseContext` ‚Äî –æ–±'—î–¥–Ω—É—î documents + slide_video_mappings
- [ ] `SourceProcessor` ABC ‚Äî `process()` abstractmethod, –Ω–µ –º–æ–∂–Ω–∞ —ñ–Ω—Å—Ç–∞–Ω—Ü—ñ—é–≤–∞—Ç–∏
- [ ] `ProcessingError` —Ç–∞ `UnsupportedFormatError` exceptions
- [ ] Exports –≤ `__init__.py` –¥–ª—è –æ–±–æ—Ö –ø–∞–∫–µ—Ç—ñ–≤
- [ ] ~8 unit-—Ç–µ—Å—Ç—ñ–≤, –≤—Å—ñ –∑–µ–ª–µ–Ω—ñ
- [ ] `make check` –ø—Ä–æ—Ö–æ–¥–∏—Ç—å

---

## Pydantic-—Å—Ö–µ–º–∏

### src/course_supporter/models/source.py

```python
"""Source material schemas for ingestion pipeline."""

from datetime import datetime
from enum import StrEnum
from typing import Any

from pydantic import BaseModel, Field


class ChunkType(StrEnum):
    """Types of content chunks produced by processors."""

    TRANSCRIPT = "transcript"
    SLIDE_TEXT = "slide_text"
    SLIDE_DESCRIPTION = "slide_description"
    PARAGRAPH = "paragraph"
    HEADING = "heading"
    WEB_CONTENT = "web_content"
    METADATA = "metadata"


class ContentChunk(BaseModel):
    """Single chunk of extracted content.

    Each processor produces a list of these. The chunk_type identifies
    the source (transcript, slide text, etc.) and metadata carries
    type-specific details (timecodes, slide numbers, heading levels).
    """

    chunk_type: ChunkType
    text: str
    index: int = 0
    metadata: dict[str, Any] = Field(default_factory=dict)


class SourceDocument(BaseModel):
    """Unified output of any SourceProcessor.

    Contains all extracted content from a single source material
    (one video, one PDF, etc.) as a list of ContentChunks.
    """

    source_type: str
    source_url: str
    title: str = ""
    chunks: list[ContentChunk] = Field(default_factory=list)
    processed_at: datetime = Field(default_factory=datetime.now)
    metadata: dict[str, Any] = Field(default_factory=dict)
```

**metadata examples:**
- transcript chunk: `{"start_sec": 0.0, "end_sec": 30.0}`
- slide_text chunk: `{"slide_number": 1, "has_diagram": True}`
- heading chunk: `{"level": 2}`
- SourceDocument video: `{"duration_sec": 3600, "strategy": "gemini"}`
- SourceDocument presentation: `{"page_count": 25, "format": "pdf"}`
- SourceDocument web: `{"fetched_at": "...", "domain": "example.com"}`

### src/course_supporter/models/course.py

```python
"""Course structure schemas."""

from datetime import datetime

from pydantic import BaseModel, Field

from course_supporter.models.source import SourceDocument


class SlideVideoMapEntry(BaseModel):
    """Pydantic mirror of ORM SlideVideoMapping.

    Maps slide_number to video_timecode (e.g., "01:23:45").
    Matches ORM: String(20) for video_timecode.
    """

    slide_number: int
    video_timecode: str


class CourseContext(BaseModel):
    """Unified context for course structuring.

    Combines all processed source documents and optional
    slide-video mappings into a single object for the
    ArchitectAgent.
    """

    documents: list[SourceDocument]
    slide_video_mappings: list[SlideVideoMapEntry] = Field(default_factory=list)
    created_at: datetime = Field(default_factory=datetime.now)
```

**–ü—Ä–∏–º—ñ—Ç–∫–∞ —â–æ–¥–æ ORM:** `SlideVideoMapping` ORM –º–∞—î `video_timecode: Mapped[str] = mapped_column(String(20))` ‚Äî —Ü–µ —Ä—è–¥–æ–∫ –≤–∏–≥–ª—è–¥—É "01:23:45", –ù–ï start/end floats. Pydantic model —Ü–µ –¥–∑–µ—Ä–∫–∞–ª—é—î.

### src/course_supporter/models/__init__.py

```python
"""Pydantic schemas for course-supporter domain models."""

from course_supporter.models.course import CourseContext, SlideVideoMapEntry
from course_supporter.models.source import (
    ChunkType,
    ContentChunk,
    SourceDocument,
)

__all__ = [
    "ChunkType",
    "ContentChunk",
    "CourseContext",
    "SlideVideoMapEntry",
    "SourceDocument",
]
```

---

## SourceProcessor ABC + Exceptions

### src/course_supporter/ingestion/base.py

```python
"""SourceProcessor abstract base class and custom exceptions."""

import abc

from course_supporter.models.source import SourceDocument


class ProcessingError(Exception):
    """Raised when a processor fails to process source material."""


class UnsupportedFormatError(ProcessingError):
    """Raised when source material format is not supported by processor."""


class SourceProcessor(abc.ABC):
    """Abstract base class for all source material processors.

    Each processor transforms a SourceMaterial into a SourceDocument
    containing extracted ContentChunks.
    """

    @abc.abstractmethod
    async def process(
        self,
        source: "SourceMaterial",
        *,
        router: "ModelRouter | None" = None,
    ) -> SourceDocument:
        """Process source material and return structured document.

        Args:
            source: The source material to process.
            router: Optional ModelRouter for LLM-powered processing
                    (vision analysis, transcription via Gemini, etc.).

        Returns:
            SourceDocument with extracted content chunks.

        Raises:
            ProcessingError: If processing fails.
            UnsupportedFormatError: If source format is not supported.
        """
        ...
```

**–ü—Ä–∏–º—ñ—Ç–∫–∏ —â–æ–¥–æ type hints:**
- `SourceMaterial` —Ç–∞ `ModelRouter` ‚Äî string forward references, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ circular imports
- –ù–∞ –ø—Ä–∞–∫—Ç–∏—Ü—ñ `source` –±—É–¥–µ `course_supporter.storage.orm.SourceMaterial` (ORM model)
- `router` –±—É–¥–µ `course_supporter.llm.router.ModelRouter`

### src/course_supporter/ingestion/__init__.py

```python
"""Ingestion pipeline for processing course materials."""

from course_supporter.ingestion.base import (
    ProcessingError,
    SourceProcessor,
    UnsupportedFormatError,
)

__all__ = [
    "ProcessingError",
    "SourceProcessor",
    "UnsupportedFormatError",
]
```

---

## –¢–µ—Å—Ç–∏

### tests/unit/test_ingestion/__init__.py

–ü–æ—Ä–æ–∂–Ω—ñ–π —Ñ–∞–π–ª.

### tests/unit/test_ingestion/test_schemas.py

```python
"""Tests for ingestion pipeline schemas and interfaces."""

from datetime import datetime

import pytest

from course_supporter.ingestion.base import (
    ProcessingError,
    SourceProcessor,
    UnsupportedFormatError,
)
from course_supporter.models.source import (
    ChunkType,
    ContentChunk,
    SourceDocument,
)
from course_supporter.models.course import CourseContext, SlideVideoMapEntry


class TestChunkType:
    def test_chunk_type_values(self) -> None:
        """All expected chunk types exist with correct string values."""
        assert ChunkType.TRANSCRIPT == "transcript"
        assert ChunkType.SLIDE_TEXT == "slide_text"
        assert ChunkType.SLIDE_DESCRIPTION == "slide_description"
        assert ChunkType.PARAGRAPH == "paragraph"
        assert ChunkType.HEADING == "heading"
        assert ChunkType.WEB_CONTENT == "web_content"
        assert ChunkType.METADATA == "metadata"


class TestContentChunk:
    def test_content_chunk_default_metadata(self) -> None:
        """ContentChunk metadata defaults to empty dict."""
        chunk = ContentChunk(chunk_type=ChunkType.PARAGRAPH, text="hello")
        assert chunk.metadata == {}
        assert chunk.index == 0

    def test_content_chunk_with_timecodes(self) -> None:
        """Transcript chunk carries start/end timecodes in metadata."""
        chunk = ContentChunk(
            chunk_type=ChunkType.TRANSCRIPT,
            text="Hello world",
            index=0,
            metadata={"start_sec": 0.0, "end_sec": 30.0},
        )
        assert chunk.metadata["start_sec"] == 0.0
        assert chunk.metadata["end_sec"] == 30.0


class TestSourceDocument:
    def test_source_document_defaults(self) -> None:
        """SourceDocument has empty chunks and auto processed_at."""
        doc = SourceDocument(source_type="text", source_url="file:///test.md")
        assert doc.chunks == []
        assert doc.title == ""
        assert isinstance(doc.processed_at, datetime)
        assert doc.metadata == {}

    def test_source_document_with_chunks(self) -> None:
        """SourceDocument holds multiple content chunks."""
        chunks = [
            ContentChunk(chunk_type=ChunkType.HEADING, text="Title", index=0),
            ContentChunk(chunk_type=ChunkType.PARAGRAPH, text="Body", index=1),
        ]
        doc = SourceDocument(
            source_type="text",
            source_url="file:///test.md",
            title="My Doc",
            chunks=chunks,
        )
        assert len(doc.chunks) == 2
        assert doc.chunks[0].chunk_type == ChunkType.HEADING


class TestCourseContext:
    def test_course_context_empty(self) -> None:
        """CourseContext with no documents."""
        ctx = CourseContext(documents=[])
        assert ctx.documents == []
        assert ctx.slide_video_mappings == []
        assert isinstance(ctx.created_at, datetime)

    def test_course_context_with_mappings(self) -> None:
        """CourseContext with documents and slide-video mappings."""
        doc = SourceDocument(source_type="video", source_url="file:///v.mp4")
        mapping = SlideVideoMapEntry(slide_number=1, video_timecode="00:05:30")
        ctx = CourseContext(
            documents=[doc],
            slide_video_mappings=[mapping],
        )
        assert len(ctx.documents) == 1
        assert ctx.slide_video_mappings[0].slide_number == 1
        assert ctx.slide_video_mappings[0].video_timecode == "00:05:30"


class TestSourceProcessor:
    def test_source_processor_is_abstract(self) -> None:
        """SourceProcessor cannot be instantiated directly."""
        with pytest.raises(TypeError):
            SourceProcessor()  # type: ignore[abstract]

    def test_processing_error_hierarchy(self) -> None:
        """UnsupportedFormatError is a subclass of ProcessingError."""
        assert issubclass(UnsupportedFormatError, ProcessingError)
        assert issubclass(ProcessingError, Exception)
```

---

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª—ñ–≤

```
src/course_supporter/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py          # exports: ChunkType, ContentChunk, SourceDocument, CourseContext, SlideVideoMapEntry
‚îÇ   ‚îú‚îÄ‚îÄ source.py            # ChunkType, ContentChunk, SourceDocument
‚îÇ   ‚îî‚îÄ‚îÄ course.py            # SlideVideoMapEntry, CourseContext
‚îú‚îÄ‚îÄ ingestion/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py          # exports: SourceProcessor, ProcessingError, UnsupportedFormatError
‚îÇ   ‚îî‚îÄ‚îÄ base.py              # SourceProcessor ABC, ProcessingError, UnsupportedFormatError

tests/unit/test_ingestion/
‚îú‚îÄ‚îÄ __init__.py
‚îî‚îÄ‚îÄ test_schemas.py          # ~8 tests
```

---

## –ö—Ä–æ–∫–∏ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è

1. –ó–∞–º—ñ–Ω–∏—Ç–∏ `models/source.py` ‚Äî `ChunkType`, `ContentChunk`, `SourceDocument`
2. –ó–∞–º—ñ–Ω–∏—Ç–∏ `models/course.py` ‚Äî `SlideVideoMapEntry`, `CourseContext`
3. –û–Ω–æ–≤–∏—Ç–∏ `models/__init__.py` ‚Äî exports
4. –ó–∞–º—ñ–Ω–∏—Ç–∏ `ingestion/base.py` ‚Äî `SourceProcessor` ABC, exceptions
5. –û–Ω–æ–≤–∏—Ç–∏ `ingestion/__init__.py` ‚Äî exports
6. –°—Ç–≤–æ—Ä–∏—Ç–∏ `tests/unit/test_ingestion/__init__.py`
7. –°—Ç–≤–æ—Ä–∏—Ç–∏ `tests/unit/test_ingestion/test_schemas.py`
8. `make check`

---

## –ü—Ä–∏–º—ñ—Ç–∫–∏

- **Forward references**: `SourceMaterial` —Ç–∞ `ModelRouter` ‚Äî string refs —É —Å–∏–≥–Ω–∞—Ç—É—Ä—ñ `process()`, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ circular imports. –¢–∏–ø–∏ –¥–æ—Å—Ç—É–ø–Ω—ñ runtime —á–µ—Ä–µ–∑ `TYPE_CHECKING` –∞–±–æ –ø—Ä–æ—Å—Ç–æ —è–∫ string annotations.
- **ChunkType —è–∫ StrEnum**: Python 3.11+ StrEnum ‚Äî –∑–Ω–∞—á–µ–Ω–Ω—è chunk_type —Å–µ—Ä—ñ–∞–ª—ñ–∑—É—é—Ç—å—Å—è —è–∫ –∑–≤–∏—á–∞–π–Ω—ñ —Ä—è–¥–∫–∏ –≤ JSON, —â–æ —Å–ø—Ä–æ—â—É—î —Ä–æ–±–æ—Ç—É –∑ API —Ç–∞ –ª–æ–≥—É–≤–∞–Ω–Ω—è–º.
- **processed_at**: `datetime.now` (–±–µ–∑ UTC) ‚Äî –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î —Å—Ç–∏–ª—é `LLMResponse.finished_at` –∑ Epic 2. –ü—Ä–∏ –ø–æ—Ç—Ä–µ–±—ñ –ø–µ—Ä–µ—Ö—ñ–¥ –Ω–∞ `datetime.now(UTC)` ‚Äî –æ–∫—Ä–µ–º–∏–π —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥.
- **Pydantic vs ORM**: `SourceDocument` ‚Äî Pydantic model –¥–ª—è pipeline data flow; `SourceMaterial` ‚Äî SQLAlchemy ORM –¥–ª—è persistence. –í–æ–Ω–∏ –º–∞—é—Ç—å —Ä—ñ–∑–Ω–µ –ø—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è —ñ –Ω–µ –º–∞—é—Ç—å –Ω–∞—Å–ª—ñ–¥—É–≤–∞—Ç–∏ –æ–¥–Ω–∞ –æ–¥–Ω—É.
